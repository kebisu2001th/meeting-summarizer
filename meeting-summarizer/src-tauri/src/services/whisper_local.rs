use crate::errors::{AppError, AppResult};
use crate::models::{Transcription, TranscriptionStatus};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tokio::sync::Mutex;
use tokio::process::Command as TokioCommand;
use std::fs;
use dirs;

pub struct WhisperService {
    model_path: PathBuf,
    recordings_dir: PathBuf,
    python_path: Option<PathBuf>,
    whisper_command: String,
    initialized: Arc<Mutex<bool>>,
    model_size: String,
}

impl WhisperService {
    pub fn new(model_path: PathBuf, recordings_dir: PathBuf) -> Self {
        // ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ç’°å¢ƒå¤‰æ•°ã§è¨­å®šå¯èƒ½ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: small - é€Ÿåº¦é‡è¦–ï¼‰
        let model_size = std::env::var("WHISPER_MODEL_SIZE")
            .unwrap_or_else(|_| "small".to_string());
        
        // Pythonãƒ‘ã‚¹ã‚’è‡ªå‹•æ¤œå‡º
        let python_path = Self::detect_python_path();
        
        // whisperã‚³ãƒãƒ³ãƒ‰ã‚’è¨­å®š
        let whisper_command = std::env::var("WHISPER_COMMAND")
            .unwrap_or_else(|_| "whisper".to_string());
        
        Self {
            model_path,
            recordings_dir,
            python_path,
            whisper_command,
            initialized: Arc::new(Mutex::new(false)),
            model_size,
        }
    }

    pub async fn initialize(&self) -> AppResult<()> {
        let mut initialized = self.initialized.lock().await;
        
        if *initialized {
            return Ok(());
        }

        log::info!("ğŸ”„ ãƒ­ãƒ¼ã‚«ãƒ«WhisperåˆæœŸåŒ–ä¸­...");

        // Pythonã®å­˜åœ¨ç¢ºèª
        if !self.check_python_available().await? {
            return Err(AppError::WhisperInit {
                message: "Python not found. Please install Python 3.8 or later.".to_string(),
            });
        }

        // whisperãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å­˜åœ¨ç¢ºèª
        if !self.check_whisper_available().await? {
            log::warn!("Whisper library not found. Attempting to install...");
            self.install_whisper().await?;
        }

        // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç¢ºèª
        self.ensure_model_downloaded().await?;

        *initialized = true;
        log::info!("âœ… ãƒ­ãƒ¼ã‚«ãƒ«WhisperåˆæœŸåŒ–å®Œäº† (ãƒ¢ãƒ‡ãƒ«: {})", self.model_size);
        
        Ok(())
    }

    pub async fn is_initialized(&self) -> bool {
        let initialized = self.initialized.lock().await;
        *initialized
    }

    pub async fn transcribe_audio_file(
        &self,
        audio_path: &Path,
        recording_id: String,
        language: Option<String>,
    ) -> AppResult<Transcription> {
        let start_time = std::time::Instant::now();
        
        // åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯
        if !self.is_initialized().await {
            return Err(AppError::WhisperNotInitialized {
                message: "Whisper service is not initialized. Call initialize() first.".to_string(),
            });
        }

        // ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if !audio_path.exists() {
            return Err(AppError::FileNotFound {
                path: audio_path.to_string_lossy().to_string(),
            });
        }

        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ500MBåˆ¶é™ã€1KBæœ€å°ï¼‰
        let file_size = fs::metadata(audio_path)?.len();
        if file_size > 500 * 1024 * 1024 {
            return Err(AppError::TranscriptionFailed {
                message: "Audio file too large. Maximum size is 500MB for local processing.".to_string(),
            });
        }
        if file_size < 1024 {
            return Err(AppError::TranscriptionFailed {
                message: "Audio file too small. Minimum size is 1KB.".to_string(),
            });
        }

        log::info!("ğŸ¤ ãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°æ›¸ãèµ·ã“ã—é–‹å§‹: {:?}", audio_path);

        // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        let output_dir = self.recordings_dir.join("transcripts");
        fs::create_dir_all(&output_dir)?;
        let output_file = output_dir.join(format!("{}.txt", recording_id));

        // whisperã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
        let transcription_text = self.run_whisper_command(
            audio_path,
            &output_file,
            language.as_deref()
        ).await?;

        let processing_time = start_time.elapsed().as_millis() as u64;
        
        // è»¢å†™çµæœã‚’ä½œæˆ
        let transcription = Transcription::new(
            recording_id,
            transcription_text,
            language.unwrap_or_else(|| "ja".to_string()),
        )
        .with_confidence(Some(0.95)) // ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ãªã®ã§é«˜ã„ä¿¡é ¼åº¦ã‚’è¨­å®š
        .with_processing_time(Some(processing_time))
        .with_status(TranscriptionStatus::Completed);

        log::info!("âœ… ãƒ­ãƒ¼ã‚«ãƒ«æ›¸ãèµ·ã“ã—å®Œäº†: {} æ–‡å­— ({}ms)", 
                  transcription.text.len(), processing_time);

        Ok(transcription)
    }

    async fn run_whisper_command(
        &self,
        audio_path: &Path,
        output_file: &Path,
        language: Option<&str>,
    ) -> AppResult<String> {
        // Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦Whisperã‚’å®Ÿè¡Œ
        let python_cmd = self.python_path.as_ref()
            .map(|p| p.to_string_lossy().to_string())
            .unwrap_or_else(|| "python3".to_string());

        // Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ
        let script = self.create_whisper_script(audio_path, language).await?;
        
        log::debug!("å®Ÿè¡ŒPython: {} -c '{}'", python_cmd, script);

        // Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
        let mut cmd = TokioCommand::new(&python_cmd);
        cmd.arg("-c").arg(&script);

        let output = cmd.output().await
            .map_err(|e| AppError::TranscriptionFailed {
                message: format!("Failed to execute whisper Python script: {}", e),
            })?;

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            let stdout = String::from_utf8_lossy(&output.stdout);
            log::error!("Whisper command failed. stderr: {}, stdout: {}", stderr, stdout);
            return Err(AppError::TranscriptionFailed {
                message: format!("Whisper transcription failed: {}", stderr),
            });
        }

        // stdoutã‹ã‚‰çµæœã‚’å–å¾—
        let stdout = String::from_utf8_lossy(&output.stdout);
        let stderr = String::from_utf8_lossy(&output.stderr);
        
        log::debug!("Whisper stdout: {}", stdout);
        log::debug!("Whisper stderr: {}", stderr);
        
        let result = stdout.trim().to_string();
        
        // ç©ºã®çµæœã§ã‚‚ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„ï¼ˆç„¡éŸ³ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãªã©ï¼‰
        if result.is_empty() {
            log::warn!("Whisper returned empty result. stdout: '{}', stderr: '{}'", stdout, stderr);
            return Ok("ï¼ˆç„¡éŸ³ã¾ãŸã¯èªè­˜ã§ããªã„éŸ³å£°ï¼‰".to_string());
        }

        Ok(result)
    }

    async fn create_whisper_script(
        &self,
        audio_path: &Path,
        language: Option<&str>,
    ) -> AppResult<String> {
        // æ—¥æœ¬èªã®å ´åˆã¯æ˜ç¤ºçš„ã«è¨€èªæŒ‡å®šã¨æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        let language = language.unwrap_or("ja");
        let is_japanese = language == "ja";
        
        // æ—¥æœ¬èªå°‚ç”¨ã®é«˜é€Ÿãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé€Ÿåº¦é‡è¦–ï¼‰
        let transcribe_options = if is_japanese {
            format!(
                r#"language='ja',
                task='transcribe',
                temperature=0.2,
                best_of=1,
                beam_size=1,
                patience=1.0,
                length_penalty=1.0,
                suppress_tokens=[-1],
                word_timestamps=False,
                condition_on_previous_text=True"#
            )
        } else {
            format!("language='{}', temperature=0.2, best_of=1, beam_size=1", language)
        };

        let script = format!(
            r#"
import whisper
import sys
import warnings
import os
import numpy as np
warnings.filterwarnings("ignore")

try:
    audio_file = '{audio_path}'
    if not os.path.exists(audio_file):
        print(f"Error: Audio file not found: {{audio_file}}", file=sys.stderr)
        sys.exit(1)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    file_size = os.path.getsize(audio_file)
    if file_size == 0:
        print("Audio file is empty", file=sys.stderr)
        sys.exit(1)
    
    print(f"Loading model: {model_size} (optimized for Japanese)", file=sys.stderr)
    model = whisper.load_model('{model_size}')
    
    print(f"Transcribing file: {{audio_file}} ({{file_size}} bytes) with Japanese optimization", file=sys.stderr)
    
    # éŸ³å£°å‰å‡¦ç†ï¼ˆãƒã‚¤ã‚ºé™¤å»ã¨ãƒœãƒªãƒ¥ãƒ¼ãƒ æ­£è¦åŒ–ï¼‰
    try:
        import librosa
        # librosaã§éŸ³å£°ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†
        audio_data, sr = librosa.load(audio_file, sr=16000)
        # RMSãƒ™ãƒ¼ã‚¹ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ æ­£è¦åŒ–
        rms = np.sqrt(np.mean(audio_data**2))
        if rms > 0:
            target_rms = 0.1
            audio_data = audio_data * (target_rms / rms)
        # ç„¡éŸ³éƒ¨åˆ†ã®é™¤å»
        audio_data, _ = librosa.effects.trim(audio_data, top_db=30)
        print(f"Audio preprocessing completed with librosa", file=sys.stderr)
        
        # å‰å‡¦ç†æ¸ˆã¿éŸ³å£°ã§ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³
        result = model.transcribe(
            audio_data,
            {transcribe_options}
        )
    except ImportError:
        print(f"librosa not available, using direct file processing", file=sys.stderr)
        # æ—¥æœ¬èªæœ€é©åŒ–è¨­å®šã§ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥ï¼‰
        result = model.transcribe(
            audio_file,
            {transcribe_options}
        )
    
    text = result.get('text', '').strip()
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
    if 'segments' in result:
        total_segments = len(result['segments'])
        print(f"Processed {{total_segments}} audio segments", file=sys.stderr)
        
        # ä¿¡é ¼åº¦ã®ä½ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ¤œå‡º
        low_confidence_segments = 0
        for segment in result['segments']:
            if 'avg_logprob' in segment and segment['avg_logprob'] < -0.8:
                low_confidence_segments += 1
        
        if low_confidence_segments > 0:
            print(f"Warning: {{low_confidence_segments}} segments have low confidence", file=sys.stderr)
    
    if not text:
        # å®Ÿéš›ã®éŸ³å£°ãŒèªè­˜ã§ããªã„å ´åˆ
        print(f"Warning: No text could be transcribed from audio", file=sys.stderr)
        print(f"Audio file size: {{file_size}} bytes", file=sys.stderr)
        print("éŸ³å£°ãŒèªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚ˆã‚Šæ˜ç­ã«è©±ã™ã‹ã€ãƒã‚¤ã‚¯ã®è·é›¢ã‚’è¿‘ã¥ã‘ã¦ãã ã•ã„ã€‚")
    else:
        # æ—¥æœ¬èªã®å ´åˆã€å¾Œå‡¦ç†ã§æ”¹å–„
        if '{language}' == 'ja':
            # æ—¥æœ¬èªç‰¹æœ‰ã®å¾Œå‡¦ç†
            import re
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆã¨å¹»è¦šãƒ‘ã‚¿ãƒ¼ãƒ³ã®é™¤å»
            hallucination_patterns = [
                'æ—¥æœ¬èªã®éŸ³å£°ã§ã™ï¼š',
                'ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ï¼š',
                'æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚',
                'ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚',
                'ãŠç–²ã‚Œæ§˜ã§ã—ãŸã€‚',
                'æ¬¡å›ã¯ãŠæ¥½ã—ã¿ã«',
                'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚',
                'ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ'
            ]
            
            for pattern in hallucination_patterns:
                # å¹»è¦šãƒ‘ã‚¿ãƒ¼ãƒ³ã®é™¤å»
                while pattern in text:
                    text = text.replace(pattern, '', 1).strip()
            
            # ä¸è¦ãªç©ºç™½ã‚’å‰Šé™¤
            text = re.sub(r'\s+', ' ', text).strip()
            # å¥èª­ç‚¹ã®æ­£è¦åŒ–
            text = text.replace('ã€', 'ã€').replace('ã€‚', 'ã€‚')
            # è‹±æ•°å­—å‘¨ã‚Šã®ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
            text = re.sub(r'([ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¯])([A-Za-z0-9])', r'\1 \2', text)
            text = re.sub(r'([A-Za-z0-9])([ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¯])', r'\1 \2', text)
            
            # ç©ºã®çµæœã«ãªã£ãŸå ´åˆã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            if not text.strip():
                text = "éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        print(text)
        
except Exception as e:
    print(f"Error: {{e}}", file=sys.stderr)
    import traceback
    traceback.print_exc(file=sys.stderr)
    sys.exit(1)
"#,
            audio_path = audio_path.to_string_lossy(),
            model_size = self.model_size,
            transcribe_options = transcribe_options,
            language = language
        );

        Ok(script)
    }

    async fn check_python_available(&self) -> AppResult<bool> {
        let python_cmd = if let Some(python_path) = &self.python_path {
            python_path.to_string_lossy().to_string()
        } else {
            "python3".to_string()
        };

        let output = TokioCommand::new(&python_cmd)
            .arg("--version")
            .output()
            .await;

        match output {
            Ok(result) if result.status.success() => {
                let version = String::from_utf8_lossy(&result.stdout);
                log::info!("Python detected: {}", version.trim());
                Ok(true)
            }
            _ => {
                // python3ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€pythonã‚’è©¦ã™
                let output = TokioCommand::new("python")
                    .arg("--version")
                    .output()
                    .await;
                
                match output {
                    Ok(result) if result.status.success() => {
                        let version = String::from_utf8_lossy(&result.stdout);
                        log::info!("Python detected: {}", version.trim());
                        Ok(true)
                    }
                    _ => Ok(false)
                }
            }
        }
    }

    async fn check_whisper_available(&self) -> AppResult<bool> {
        // pipã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        let python_cmd = self.python_path.as_ref()
            .map(|p| p.to_string_lossy().to_string())
            .unwrap_or_else(|| "python3".to_string());

        let output = TokioCommand::new(&python_cmd)
            .arg("-c")
            .arg("import whisper; print('whisper available')")
            .output()
            .await;

        match output {
            Ok(result) if result.status.success() => Ok(true),
            _ => Ok(false)
        }
    }

    async fn install_whisper(&self) -> AppResult<()> {
        log::info!("ğŸ“¦ Whisperãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...");

        let python_cmd = self.python_path.as_ref()
            .map(|p| p.to_string_lossy().to_string())
            .unwrap_or_else(|| "python3".to_string());

        // å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒªã‚¹ãƒˆï¼ˆéŸ³å£°å‡¦ç†ã®å“è³ªå‘ä¸Šã®ãŸã‚ï¼‰
        let packages = vec![
            "openai-whisper",
            "librosa",
            "soundfile",
            "numpy",
        ];

        for package in packages {
            log::info!("ğŸ“¦ Installing {}...", package);
            
            let output = TokioCommand::new(&python_cmd)
                .arg("-m")
                .arg("pip")
                .arg("install")
                .arg(package)
                .arg("--user") // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
                .output()
                .await
                .map_err(|e| AppError::WhisperInit {
                    message: format!("Failed to install {}: {}", package, e),
                })?;

            if !output.status.success() {
                let stderr = String::from_utf8_lossy(&output.stderr);
                log::warn!("Failed to install {}: {}", package, stderr);
                // librosaç­‰ã®å¤±æ•—ã¯è‡´å‘½çš„ã§ã¯ãªã„ãŸã‚ã€whisperã®ã¿å¿…é ˆã¨ã™ã‚‹
                if package == "openai-whisper" {
                    return Err(AppError::WhisperInit {
                        message: format!("Whisper installation failed: {}", stderr),
                    });
                }
            } else {
                log::info!("âœ… {} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†", package);
            }
        }

        log::info!("âœ… éŸ³å£°å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†");
        Ok(())
    }

    async fn ensure_model_downloaded(&self) -> AppResult<()> {
        log::info!("ğŸ” Whisperãƒ¢ãƒ‡ãƒ«ç¢ºèªä¸­...");

        // Whisperãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
        let cache_dir = self.get_whisper_cache_dir();
        let model_file = cache_dir.join(format!("{}.pt", self.model_size));

        if model_file.exists() {
            log::info!("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªå®Œäº†: {}", model_file.display());
            return Ok(());
        }

        log::info!("ğŸ“¥ Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... (ãƒ¢ãƒ‡ãƒ«: {})", self.model_size);

        // ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        let temp_audio = self.create_dummy_audio_file().await?;

        // ãƒ€ãƒŸãƒ¼éŸ³å£°ã§whisperã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        let python_cmd = self.python_path.as_ref()
            .map(|p| p.to_string_lossy().to_string())
            .unwrap_or_else(|| "python3".to_string());

        let output = TokioCommand::new(&python_cmd)
            .arg("-c")
            .arg(&format!(
                "import whisper; model = whisper.load_model('{}'); print('Model loaded')",
                self.model_size
            ))
            .output()
            .await
            .map_err(|e| AppError::WhisperInit {
                message: format!("Failed to download model: {}", e),
            })?;

        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        let _ = fs::remove_file(&temp_audio);

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            return Err(AppError::WhisperInit {
                message: format!("Model download failed: {}", stderr),
            });
        }

        log::info!("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†");
        Ok(())
    }

    async fn create_dummy_audio_file(&self) -> AppResult<PathBuf> {
        // 1ç§’ã®ç„¡éŸ³WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        let temp_dir = std::env::temp_dir();
        let dummy_audio = temp_dir.join("dummy_audio.wav");

        // ç°¡å˜ãªç„¡éŸ³WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿
        let sample_rate = 16000u32;
        let duration_samples = sample_rate; // 1ç§’
        let mut wav_data = Vec::new();

        // WAVãƒ˜ãƒƒãƒ€ãƒ¼
        wav_data.extend_from_slice(b"RIFF");
        wav_data.extend_from_slice(&(36 + duration_samples * 2).to_le_bytes());
        wav_data.extend_from_slice(b"WAVE");
        wav_data.extend_from_slice(b"fmt ");
        wav_data.extend_from_slice(&16u32.to_le_bytes()); // fmt chunk size
        wav_data.extend_from_slice(&1u16.to_le_bytes()); // PCM format
        wav_data.extend_from_slice(&1u16.to_le_bytes()); // mono
        wav_data.extend_from_slice(&sample_rate.to_le_bytes());
        wav_data.extend_from_slice(&(sample_rate * 2).to_le_bytes()); // byte rate
        wav_data.extend_from_slice(&2u16.to_le_bytes()); // block align
        wav_data.extend_from_slice(&16u16.to_le_bytes()); // bits per sample
        wav_data.extend_from_slice(b"data");
        wav_data.extend_from_slice(&(duration_samples * 2).to_le_bytes());

        // ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ï¼ˆ16bitï¼‰
        for _ in 0..duration_samples {
            wav_data.extend_from_slice(&0i16.to_le_bytes());
        }

        fs::write(&dummy_audio, wav_data)?;
        Ok(dummy_audio)
    }

    fn get_whisper_cache_dir(&self) -> PathBuf {
        // Whisperã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        if let Some(home) = dirs::home_dir() {
            home.join(".cache").join("whisper")
        } else {
            PathBuf::from("/tmp/.whisper_cache")
        }
    }

    fn detect_python_path() -> Option<PathBuf> {
        // ä¸€èˆ¬çš„ãªPythonãƒ‘ã‚¹ã‚’ç¢ºèª
        let possible_paths = vec![
            "/usr/bin/python3",
            "/usr/local/bin/python3",
            "/opt/homebrew/bin/python3",
            "/usr/bin/python",
            "/usr/local/bin/python",
        ];

        for path in possible_paths {
            let path_buf = PathBuf::from(path);
            if path_buf.exists() {
                return Some(path_buf);
            }
        }

        None
    }

    pub async fn get_available_languages(&self) -> AppResult<Vec<String>> {
        // WhisperãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹è¨€èªä¸€è¦§
        Ok(vec![
            "ja".to_string(),    // Japanese
            "en".to_string(),    // English
            "zh".to_string(),    // Chinese
            "ko".to_string(),    // Korean
            "es".to_string(),    // Spanish
            "fr".to_string(),    // French
            "de".to_string(),    // German
            "it".to_string(),    // Italian
            "pt".to_string(),    // Portuguese
            "ru".to_string(),    // Russian
            "ar".to_string(),    // Arabic
            "hi".to_string(),    // Hindi
        ])
    }

    pub async fn get_service_status(&self) -> AppResult<String> {
        if !self.is_initialized().await {
            return Ok("Not initialized".to_string());
        }

        let python_available = self.check_python_available().await?;
        let whisper_available = self.check_whisper_available().await?;

        if python_available && whisper_available {
            Ok(format!("Local Whisper ready (model: {})", self.model_size))
        } else if !python_available {
            Ok("Python not available".to_string())
        } else {
            Ok("Whisper library not available".to_string())
        }
    }

    pub async fn get_model_info(&self) -> AppResult<String> {
        let cache_dir = self.get_whisper_cache_dir();
        let model_file = cache_dir.join(format!("{}.pt", self.model_size));
        
        if model_file.exists() {
            let metadata = fs::metadata(&model_file)?;
            let size_mb = metadata.len() / (1024 * 1024);
            Ok(format!("Model: {} ({} MB)", self.model_size, size_mb))
        } else {
            Ok(format!("Model: {} (not downloaded)", self.model_size))
        }
    }

    pub async fn get_all_models_info(&self) -> AppResult<Vec<(String, String, bool)>> {
        let models = vec![
            ("tiny".to_string(), "~39MB".to_string()),
            ("base".to_string(), "~142MB".to_string()),
            ("small".to_string(), "~461MB".to_string()),
            ("medium".to_string(), "~1.5GB".to_string()),
            ("large".to_string(), "~2.9GB".to_string()),
        ];

        let cache_dir = self.get_whisper_cache_dir();
        let mut result = Vec::new();

        for (model_name, estimated_size) in models {
            let model_file = cache_dir.join(format!("{}.pt", model_name));
            let is_downloaded = model_file.exists();
            
            let actual_size = if is_downloaded {
                let metadata = fs::metadata(&model_file)?;
                let size_mb = metadata.len() / (1024 * 1024);
                format!("{}MB", size_mb)
            } else {
                estimated_size
            };

            result.push((model_name, actual_size, is_downloaded));
        }

        Ok(result)
    }

    pub async fn download_all_models(&self) -> AppResult<()> {
        log::info!("ğŸ“¥ å…¨Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹...");
        
        let models = vec!["tiny", "base", "small", "medium", "large"];
        let total = models.len();
        
        for (index, model) in models.iter().enumerate() {
            log::info!("ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {} ({}/{})", model, index + 1, total);
            
            if let Err(e) = self.download_specific_model(model).await {
                log::error!("âŒ ãƒ¢ãƒ‡ãƒ« {} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {}", model, e);
                return Err(e);
            } else {
                log::info!("âœ… ãƒ¢ãƒ‡ãƒ« {} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†", model);
            }
        }

        log::info!("ğŸ‰ å…¨Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼");
        Ok(())
    }

    pub async fn download_specific_model(&self, model_name: &str) -> AppResult<()> {
        let python_cmd = self.python_path.as_ref()
            .map(|p| p.to_string_lossy().to_string())
            .unwrap_or_else(|| "python3".to_string());

        let script = format!(
            r#"
import whisper
import sys
import warnings
warnings.filterwarnings("ignore")

try:
    print(f"Downloading model: {}", file=sys.stderr)
    model = whisper.load_model('{}')
    print(f"Model {} loaded successfully", file=sys.stderr)
except Exception as e:
    print(f"Error downloading model {}: {{e}}", file=sys.stderr)
    sys.exit(1)
"#,
            model_name, model_name, model_name, model_name
        );

        let output = TokioCommand::new(&python_cmd)
            .arg("-c")
            .arg(&script)
            .output()
            .await
            .map_err(|e| AppError::WhisperInit {
                message: format!("Failed to download model {}: {}", model_name, e),
            })?;

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            return Err(AppError::WhisperInit {
                message: format!("Model {} download failed: {}", model_name, stderr),
            });
        }

        Ok(())
    }

    pub async fn get_available_models(&self) -> AppResult<Vec<String>> {
        Ok(vec![
            "tiny".to_string(),
            "base".to_string(),
            "small".to_string(),
            "medium".to_string(),
            "large".to_string(),
        ])
    }

    pub async fn set_model_size(&mut self, model_size: String) -> AppResult<()> {
        let available_models = self.get_available_models().await?;
        
        if !available_models.contains(&model_size) {
            return Err(AppError::ValidationError {
                message: format!("Invalid model size: {}. Available: {:?}", model_size, available_models),
            });
        }

        self.model_size = model_size;
        
        // åˆæœŸåŒ–çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã§å†åˆæœŸåŒ–ãŒå¿…è¦ï¼‰
        let mut initialized = self.initialized.lock().await;
        *initialized = false;
        
        Ok(())
    }

    pub fn get_current_model_size(&self) -> String {
        self.model_size.clone()
    }
}